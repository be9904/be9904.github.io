---
layout: post
title: Introduction to Machine Learning - Supervised Learning
date: 2023-09-15 00:19:27 +09:00
description: Lecture notes on professor Andrew Ng's machine learning course
img: 2023-09-15-intro-to-ml/cover.jpg
fig-caption: # Add figcaption (optional)
tags: [Machine Learning, Supervised Learning, Regression, Classification]
---

The contents of this post are lecture notes from professor Andrew Ng's course, 
<a href="https://www.coursera.org/learn/machine-learning" target="_blank">
  *Supervised Machine Learning: Regression and Classification*
</a>
.

### Supervised Learning

Supervised learning is a method of machine learning that learns from data **labeled** with **right answers**. Here are some example applications of supervised learning.

| Input | Output | Application |
| -------- | -------- | -------- |
| Email | Spam? (True/False) | Spam Filtering |
| Audio | Text Transcripts | Speech Recognition |
| Image, Radar info | Position of other cars | Self-driving cars |

There are two types of supervised learning.

**Regression** is a learning method that predicts a continuous or numeric output value. It is used when the target variable is continuous and has a real number value, like house price prediction and predicting a human's age based on various features. 
There are infinitely many possible outputs in regression.

**Classification** is a learning method that predicts a categorical or discrete output label/class. It is used when the target variable is a category, like spam filtering and image classification. In this case, there are only a small and limited number of possible outputs.

### Linear Regression

As mentioned above, regression learns from **right answers**. Linear regression is a type of regression that models the relationship between a dependent variable and one or more independent variables with a linear equation. The goal of linear regression is to find the linear equation that best fits the relationship between variables.

<p align="center">
  <img src="/assets/img/2023-09-15-intro-to-ml/01/linear-regression.png" width="80%" height="80%">
 </p>
<p align="center"><b><i>Linear Regression</i></b></p>

Linear regression with a single feature \\(x\\) is mathematically expressed as follows.

\\[f_{w, b}(x) = wx + b\\]

* \\(x\\) : input variable feature
* \\(y\\) : output variable feature / *target* variable
* \\(\hat y\\) : prediction (estimated y)
* \\(m\\) : number of training examples
* \\((x, y)\\) : single training example
* \\((x^{(i)}, y^{(i)})\\) : \\(i^{th}\\) training example

### Cost Function